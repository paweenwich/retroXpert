{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from data import *\n",
    "from model.gat import *\n",
    "from util.misc import CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    pass\n",
    "args = Args()\n",
    "args.__dict__ = {\n",
    "    \"batch_size\":32,\n",
    "    \"dataset\":'USPTO50K',\n",
    "    \"epochs\":80,\n",
    "    \"exp_name\":'USPTO50K_typed',\n",
    "    \"gat_layers\":3, \n",
    "    \"heads\":4, \n",
    "    \"hidden_dim\":128, \n",
    "    \"in_dim\":714, \n",
    "    \"load\":False, \n",
    "    \"logdir\":'logs', \n",
    "    \"lr\":0.0005, \n",
    "    \"seed\":123, \n",
    "    \"test_on_train\":False, \n",
    "    \"test_only\":False, \n",
    "    \"typed\":True, \n",
    "    \"use_cpu\":True, \n",
    "    \"valid_only\":False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Args object at 0x00000076F3040608>\n"
     ]
    }
   ],
   "source": [
    "def collate(data):\n",
    "    return map(list, zip(*data))\n",
    "    \n",
    "batch_size = args.batch_size\n",
    "epochs = args.epochs\n",
    "data_root = os.path.join('data', args.dataset)\n",
    "args.exp_name = args.dataset\n",
    "if args.typed:\n",
    "    args.in_dim += 10\n",
    "    args.exp_name += '_typed'\n",
    "else:\n",
    "    args.exp_name += '_untyped'\n",
    "print(args)\n",
    "\n",
    "test_id = '{}'.format(args.logdir)\n",
    "filename = 'logs/' + test_id + '.csv'\n",
    "csv_logger = CSVLogger(\n",
    "    args=args,\n",
    "    fieldnames=['epoch', 'train_acc', 'valid_acc', 'train_loss'],\n",
    "    filename=filename,\n",
    ")\n",
    "\n",
    "GAT_model = GATNet(\n",
    "    in_dim=args.in_dim,\n",
    "    num_layers=args.gat_layers,\n",
    "    hidden_dim=args.hidden_dim,\n",
    "    heads=args.heads,\n",
    "    use_gpu=(args.use_cpu == False),\n",
    ")\n",
    "\n",
    "if args.use_cpu:\n",
    "    device = 'cpu'\n",
    "else:\n",
    "    GAT_model = GAT_model.cuda()\n",
    "    device = 'cuda:0'\n",
    "\n",
    "if args.load:\n",
    "    GAT_model.load_state_dict(\n",
    "        torch.load('checkpoints/{}_checkpoint.pt'.format(args.exp_name),\n",
    "                    map_location=torch.device(device)), )\n",
    "    args.lr *= 0.2\n",
    "    milestones = []\n",
    "else:\n",
    "    milestones = [20, 40, 60, 80]\n",
    "\n",
    "optimizer = torch.optim.Adam([{\n",
    "    'params': GAT_model.parameters()\n",
    "}],\n",
    "                                lr=args.lr)\n",
    "scheduler = MultiStepLR(optimizer, milestones=milestones, gamma=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [15:25:50] Enabling RDKit 2019.09.3 jupyter extensions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 3482, 0: 1415, 2: 102, 9: 1, 17: 1})\n"
     ]
    }
   ],
   "source": [
    "valid_data = RetroCenterDatasets(root=data_root, data_split='valid')\n",
    "valid_dataloader = DataLoader(valid_data,\n",
    "                                batch_size=4 * batch_size,\n",
    "                                shuffle=False,\n",
    "                                num_workers=0,\n",
    "                                collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 27851, 0: 11296, 2: 849, 3: 4, 4: 4, 10: 2, 7: 1, 13: 1})\n"
     ]
    }
   ],
   "source": [
    "train_data = RetroCenterDatasets(root=data_root, data_split='train')\n",
    "train_dataloader = DataLoader(train_data,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=0,\n",
    "                            collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1251 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32 32\n",
      "361 19 19\n",
      "torch.Size([361, 1]) torch.Size([19, 19]) torch.Size([19, 19])\n",
      "tensor([[ True,  True, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False],\n",
      "        [ True,  True,  True, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False],\n",
      "        [False,  True,  True,  True, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False],\n",
      "        [False, False,  True,  True,  True,  True, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False,  True,  True, False, False, False, False, False,\n",
      "         False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False,  True, False,  True,  True, False, False, False,\n",
      "         False, False, False,  True, False, False, False, False, False],\n",
      "        [False, False, False, False, False,  True,  True,  True, False, False,\n",
      "         False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False,  True,  True,  True, False,\n",
      "         False, False,  True, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False,  True,  True,  True,\n",
      "          True,  True, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False,  True,  True,\n",
      "         False, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False,  True, False,\n",
      "          True, False, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False,  True, False,\n",
      "         False,  True, False, False, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False,  True, False, False,\n",
      "         False, False,  True,  True, False, False, False, False, False],\n",
      "        [False, False, False, False, False,  True, False, False, False, False,\n",
      "         False, False,  True,  True, False, False, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False,  True,  True, False, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False,  True,  True,  True, False, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False,  True,  True,  True,  True],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True,  True, False],\n",
      "        [False, False, False, False, False, False, False, False, False, False,\n",
      "         False, False, False, False, False, False,  True, False,  True]])\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(progress_bar):\n",
    "    rxn_class, x_pattern_feat, x_atom, x_adj, x_graph, y_adj, disconnection_num = data\n",
    "    #print(i,rxn_class,x_pattern_feat,x_atom,x_adj,x_graph,y_adj,disconnection_num)\n",
    "    x_atom = list(map(lambda x: torch.from_numpy(x).float(), x_atom))\n",
    "    x_pattern_feat = list(\n",
    "        map(lambda x: torch.from_numpy(x).float(), x_pattern_feat))\n",
    "    x_atom = list(\n",
    "        map(lambda x, y: torch.cat([x, y], dim=1), x_atom,\n",
    "            x_pattern_feat))\n",
    "\n",
    "    if args.typed:\n",
    "        rxn_class = list(\n",
    "            map(lambda x: torch.from_numpy(x).float(), rxn_class))\n",
    "        x_atom = list(\n",
    "            map(lambda x, y: torch.cat([x, y], dim=1), x_atom,\n",
    "                rxn_class))\n",
    "\n",
    "    x_atom = torch.cat(x_atom, dim=0)\n",
    "    disconnection_num = torch.LongTensor(disconnection_num)\n",
    "    if not args.use_cpu:\n",
    "        x_atom = x_atom.cuda()\n",
    "        disconnection_num = disconnection_num.cuda()\n",
    "\n",
    "    x_adj = list(map(lambda x: torch.from_numpy(np.array(x)), x_adj))\n",
    "    y_adj = list(map(lambda x: torch.from_numpy(np.array(x)), y_adj))\n",
    "    if not args.use_cpu:\n",
    "        x_adj = [xa.cuda() for xa in x_adj]\n",
    "        y_adj = [ye.cuda() for ye in y_adj]\n",
    "\n",
    "    mask = list(map(lambda x: x.view(-1, 1).bool(), x_adj))    \n",
    "    print(len(mask),len(x_adj),len(y_adj))\n",
    "    print(len(mask[0]),len(x_adj[0]),len(y_adj[0]))\n",
    "    print(mask[0].size(),x_adj[0].size(),y_adj[0].size())\n",
    "    print(y_adj[0])\n",
    "    #print(mask[1].size(),x_adj[1].size(),y_adj[1].view(-1, 1).size())\n",
    "    # bond_connections = list(\n",
    "    #     map(lambda x, y: torch.masked_select(x.view(-1, 1), y), y_adj,mask)\n",
    "    # )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19, 19])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-7.2330e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2331e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2332e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2333e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2333e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2334e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2335e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2336e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2336e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2337e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2338e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4399e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2339e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2339e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2340e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2341e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2342e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2342e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2343e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2344e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2345e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2345e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2346e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2347e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2348e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2348e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2349e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2350e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.2350e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3905e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3905e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3906e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3907e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3908e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3908e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3909e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3910e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3911e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3911e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3912e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3913e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3914e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3914e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3915e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3916e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3916e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3917e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3918e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3919e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3919e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3920e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3921e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3922e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3922e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3923e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3924e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3925e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3925e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3926e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3927e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3928e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3928e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3929e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3930e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3931e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3931e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3932e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3933e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3934e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3934e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.3935e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4253e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4254e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4255e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4255e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4256e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4257e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4258e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4258e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4259e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4260e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4261e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4261e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4262e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4263e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4264e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4264e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4265e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4266e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4267e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4267e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4268e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4269e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4270e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4270e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4271e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4272e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4273e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4273e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4274e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4275e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4275e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4276e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4277e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4278e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4278e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4279e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4280e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4281e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4281e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4282e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4283e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.4284e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5838e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5838e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5839e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5840e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5841e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5841e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5842e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5843e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5844e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5844e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5845e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5846e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5847e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5847e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5848e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5849e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5850e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5850e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5851e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5852e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5853e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5853e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5854e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5855e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5856e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5856e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5857e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5858e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5859e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5859e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5860e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5861e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5862e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5862e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5863e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5864e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5864e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5865e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5866e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5867e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5867e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5868e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5584e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5585e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5586e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5586e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5587e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5588e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5589e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5589e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5590e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5591e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5592e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5592e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5593e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5594e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5595e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5595e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5596e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5597e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5598e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5598e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5599e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5600e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5601e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5601e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5602e+32],\n",
       "        [ 1.6535e-43],\n",
       "        [-7.5603e+32]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.empty(19,19)\n",
    "print(y.size())\n",
    "y.view(-1,1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('retroXpert')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e96683d29ed685688ca04abe69e8a61a5d587eed448109638a4988517c04595"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
